<section xml:id="ch3sec1">

<title>Section 3.1</title>
    <!--Activity 2.1.1-->

 <activity>
      <statement>
      <p> Let's consider the matrices
      <me>
  A = \left[\begin{array}{rrr}
  1 \amp 0 \amp 2 \\
  2 \amp 2 \amp 1 \\
  1 \amp 1 \amp 1 \\
  \end{array}\right],
  B = \left[\begin{array}{rrr}
  1 \amp 2 \amp -4 \\
  -1 \amp -1 \amp 3 \\
  0 \amp -1 \amp 2 \\
  \end{array}\right]
      </me>.
  <ol label="a.">
    <li><p> Define these matrices in Sage and verify that <m>BA =
    I</m> so that <m>B=A^{-1}</m>.
    <sage>
      <input>
      </input>
    </sage>
    </p></li>

    <li><p>Find the solution to the equation <m>A\xvec =
    \threevec{4}{-1}{4}</m> using <m>A^{-1}</m>.  </p></li>

    <li><p> Using your Sage cell above, multiply <m>A</m> and
    <m>B</m> in the opposite order;  that is, what do you find
    when you evaluate <m>AB</m>? </p></li>
  </ol></p></statement></activity>

<activity>
      <statement>
        
    <p> Suppose that <m>A</m> is an <m>n\times n</m>
    invertible matrix with inverse <m>A^{-1}</m>.  This means
    that every equation of the form <m>A\xvec=\bvec</m> has a
    solution, namely, <m>\xvec = A^{-1}\bvec</m>. Which of the following best describes 
    a restatement of this fact?
    <ol label ="a">
      <li><p>The columns of <m>A</m> are linearly independent.</p></li>
      <li><p>The columns of <m>A</m> span <m>\real^3</m>.</p></li>
    </ol>
    </p></statement></activity>

    <activity>
      <statement>
        
    <p> Suppose that <m>A</m> is an <m>n\times n</m>
    invertible matrix with inverse <m>A^{-1}</m>.  This means
    that every equation of the form <m>A\xvec=\bvec</m> has a
    solution, namely, <m>\xvec = A^{-1}\bvec</m>.  What can you conclude about the pivot positions of the
    matrix <m>A</m>? 

  <ol label ="a">
      <li><p>Every column of <m>A</m> has a pivot position.</p></li>
      <li><p>Every row of <m>A</m> has a pivot position.</p></li>
      <li><p>Every row and every column of <m>A</m> has a pivot position.</p></li>
    </ol></p></statement></activity>

    <activity>
      <statement>
    <p> If <m>A</m> is an invertible <m>4\times4</m> matrix,
    what is its reduced row echelon form? </p>
      </statement>

      <!--<solution>
  <p><ol label="a.">
    <li><p>
      We compute that
      <me>
        \left[\begin{array}{rrr}
        1 \amp 2 \amp -4 \\
        -1 \amp -1 \amp 3 \\
        0 \amp -1 \amp 2
        \end{array}\right]
        \left[\begin{array}{rrr}
        1 \amp 0 \amp 2 \\
        2 \amp 2 \amp 1 \\
        1 \amp 1 \amp 1
        \end{array}\right]
        =
        \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        0 \amp 1 \amp 0 \\
        0 \amp 0 \amp 1
        \end{array}\right]
      </me>
      showing that <m>B=A^{-1}</m>.
    </p></li>

    <li><p>
      Since we have <m>B=A^{-1}</m>, we compute
      <m>\xvec=B\threevec{4}{-1}{4} = \threevec{-14}{9}{9}</m>.
    </p></li>

    <li><p>
      We also see that <m>AB=I</m>.
    </p></li>

    <li><p>
      Since the equation <m>A\xvec=\bvec</m> is consistent for
      every <m>\bvec</m>, the columns of <m>A</m> must span
      <m>\real^n</m>.
    </p></li>

    <li><p>
      This means that there is a pivot position in every row.
      Since the matrix has the same number of rows and columns,
      there is also a pivot position in every column.
    </p></li>

    <li><p>
      Since there is a pivot position in every row and every
      column, the reduced row echelon form of <m>A</m> is the
      identity matrix <m>I</m>.
    </p></li>
  </ol></p>
      </solution>-->

    </activity>

    <activity>
      <statement>
      <p> In this activity, we let
      <me>
  A = \left[\begin{array}{rr}
  1 \amp 2 \\
  1 \amp 3 \\
  \end{array}\right]
      </me>
      and construct its inverse <m>A^{-1}</m>.
      For the time being, let's denote the inverse by <m>B</m> so that
      <m>B=A^{-1}</m>.
      </p>

      <ol label="a.">
  <li><p> We know that <m>AB = I</m>.  If we write
  <m>B = \left[\begin{array}{rr}\bvec_1\amp
  \bvec_2\end{array}\right]</m>, then we have
  <me>
    AB = \left[\begin{array}{rr}
    A\bvec_1 \amp A\bvec_2
    \end{array}\right] =
    \left[\begin{array}{rr}
    \evec_1 \amp \evec_2
    \end{array}\right] = I
  </me>.
  This means that we need to solve the equations
  <me>
    \begin{aligned}
    A\bvec_1 \amp {}={} \evec_1 \\
    A\bvec_2 \amp {}={} \evec_2 \\
    \end{aligned}
  </me>.
  Using the Sage cell below, solve these equations for the
  columns of <m>B</m>.
  <sage>
    <input>
    </input>
  </sage>
  </p></li>

  <li><p> What is the matrix <m>B</m>?  Check that <m>AB = I</m>
  and <m>BA = I</m>.
  <sage>
    <input>
    </input>
  </sage>
  </p></li>

  <li><p> To find the columns of <m>B</m>, we solved two
  equations, <m>A\bvec_1=\evec_1</m> and
  <m>A\bvec_2=\evec_2</m>.  We could do this by augmenting
  <m>A</m> two separate times, forming matrices
  <me>
    \begin{aligned}
    \left[\begin{array}{r|r} A \amp \evec_1 \end{array}\right] \amp
    \\
    \left[\begin{array}{r|r} A \amp \evec_2 \end{array}\right] \amp
    \\
    \end{aligned}
  </me>
  and finding their reduced row echelon forms.
  But instead of
  solving these two equations separately, we could also solve them
  together by forming the augmented matrix
  <m>
    \left[\begin{array}{r|rr} A \amp \evec_1 \amp \evec_2
    \end{array}\right]
  </m>
  and finding the row reduced echelon form.  In other words, we
  augment <m>A</m> by the matrix <m>I</m> to form
  <m>\left[\begin{array}{r|r}
  A \amp I \end{array}
  \right]
  </m>.
      </p>
      <p>
  Form this augmented matrix and find its reduced row echelon
  form to find <m>A^{-1}</m>.
  <sage>
    <input>
    </input>
  </sage>
      </p></li></ol></statement></activity>

  <p> Assuming <m>A</m> is invertible, we have shown that
      <me>
  \left[\begin{array}{r|r}
  A \amp I
  \end{array}\right]
  \sim 
  \left[\begin{array}{r|r}
  I \amp A^{-1}
  \end{array}\right]
      </me>.
  </p>

<activity>
      <statement>
 <p> If you have defined a matrix <m>A</m> in Sage, you can
  find it's inverse as <c>A.inverse()</c>.  Use Sage to find the
  inverse of the matrix
  <me>
    A = \left[\begin{array}{rrr}
    1 \amp -2 \amp -1 \\
    -1 \amp 5 \amp 6 \\
    5 \amp -4 \amp 6 \\
    \end{array}\right]
  </me>.
  <sage>
    <input>
    </input>
  </sage>
  </p></statement></activity>

  <activity>
      <statement>

  <p> What happens when we try to find the inverse of the
  matrix
  <me>
    \left[\begin{array}{rr}
    -4 \amp 2 \\
    -2 \amp 1 \\
    \end{array}\right]
  </me>?
  </p></statement></activity>

  <activity>
      <statement>

  <p> Suppose that <m>n\times n</m> matrices <m>C</m> and
  <m>D</m> are both invertible.  What do you find when you
  simplify the product <m>(D^{-1}C^{-1})(CD)</m>?  Explain why this shows
  the product <m>CD</m> is invertible and <m>(CD)^{-1} =
  D^{-1}C^{-1}</m>.  </p>
      
      </statement>

      <!--<solution>
  <p><ol label="a.">
    <li><p>
      Solving these two equations shows that
      <me>\bvec_1=\twovec{3}{-1}, \bvec_2=\twovec{-2}{1}\text{.}
      </me>
    </p></li>

    <li><p>
      Since the vectors <m>\bvec_1</m> and <m>\bvec_2</m> form
      the columns of <m>B</m>, we have
      <m>
        B=\left[\begin{array}{rr}
        3 \amp -2 \\
        -1 \amp 1 \\
        \end{array}\right]
      </m>.
      We can then verify by multiplying that <m>AB=BA=I</m>.
    </p></li>

    <li><p>
      We construct the augmented matrix
      <me>
        \left[\begin{array}{rr|rr}
        1 \amp 2 \amp 1 \amp 0 \\
        1 \amp 3 \amp 0 \amp 1
        \end{array}\right]
        \sim
        \left[\begin{array}{rr|rr}
        1 \amp 0 \amp 3 \amp -2 \\
        0 \amp 1 \amp -1 \amp 1
        \end{array}\right]\text{,}
      </me>
      which shows that <m>A^{-1}=\left[\begin{array}{rr}
      3 \amp -2 \\
      -1 \amp 1 \\
      \end{array}\right]
      </m>.
    </p></li>

    <li><p>
      Using Sage, we find that
      <m>A^{-1}=
      \left[\begin{array}{rrr}
      -\frac{18}{35} \amp -\frac{16}{105} \amp \frac{1}{15} \\
      -\frac{12}{35} \amp \frac{1}{105} \amp -\frac{1}{15} \\
      \frac{1}{5} \amp \frac{2}{15} \amp \frac{1}{15}
      \end{array}\right]
      </m>.
    </p></li>

    <li><p>
      This matrix does not have an inverse because its reduced
      row echelon form is not the identity <m>I</m>.
    </p></li>

    <li><p>
      We find that <m>(D^{-1}C^{-1})(CD) = I</m> so <m>(CD)^{-1}
      = D^{-1}C^{-1}</m>.
    </p></li>
  </ol></p>
      </solution>-->

    </activity>

    <p>We have seen how to use Gaussian elimination to find the inverse of a matrix. Now we wan to look at how to use matrix multiplication to perform Gaussian Elinmination.</p>

    <activity estimated-time='20'>
    <introduction>
        <p>
Tweaking the identity matrix slightly allows us to write row operations
in terms of matrix multiplication.
        </p>
    </introduction>
<task>
    <p>
Create a matrix that doubles the third row of <m>A</m>:
<me>
 \left[\begin{array}{ccc} \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \end{array}\right]
 \left[\begin{array}{ccc} 2 &amp; 7 &amp; -1 \\ 0 &amp; 3 &amp; 2 \\ 1 &amp; 1 &amp; -1 \end{array}\right]
=
 \left[\begin{array}{ccc} 2 &amp; 7 &amp; -1 \\ 0 &amp; 3 &amp; 2 \\ 2 &amp; 2 &amp; -2 \end{array}\right]
</me>
    </p>
</task>
<task>
    <p>
  Create a matrix that swaps the second and third rows of <m>A</m>:
  <me>
   \left[\begin{array}{ccc} \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \end{array}\right]
   \left[\begin{array}{ccc} 2 &amp; 7 &amp; -1 \\ 0 &amp; 3 &amp; 2 \\ 1 &amp; 1 &amp; -1 \end{array}\right]
  =
  \left[\begin{array}{ccc} 2 &amp; 7 &amp; -1 \\ 1 &amp; 1 &amp; -1 \\ 0 &amp; 3 &amp; 2 \end{array}\right]
  </me>
    </p>
</task>
<task>
    <p>
Create a matrix that adds <m>5</m> times the third row of <m>A</m> to the first row:
<me>
 \left[\begin{array}{ccc} \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \\ \unknown &amp; \unknown &amp; \unknown \end{array}\right]
 \left[\begin{array}{ccc} 2 &amp; 7 &amp; -1 \\ 0 &amp; 3 &amp; 2 \\ 1 &amp; 1 &amp; -1 \end{array}\right]
=
 \left[\begin{array}{ccc} 2+5(1) &amp; 7+5(1) &amp; -1+5(-1) \\ 0 &amp; 3 &amp; 2 \\ 1 &amp; 1 &amp; -1 \end{array}\right]
</me>
    </p>
</task>
</activity>

<activity estimated-time='10'>
    <statement>
        <p>
Consider the two row operations 
<m>R_2\leftrightarrow R_3</m> and <m>R_1+R_2\to R_1</m>
applied as follows to show <m>A\sim B</m>:
        </p>
        <md>
            <mrow>
A
  =
\left[\begin{array}{ccc}
-1&amp;4&amp;5\\
0&amp;3&amp;-1\\
1&amp;2&amp;3\\
\end{array}\right]
  &amp;\sim
\left[\begin{array}{ccc}
-1&amp;4&amp;5\\
1&amp;2&amp;3\\
0&amp;3&amp;-1\\
\end{array}\right]
            </mrow>
            <mrow>
  &amp;\sim
\left[\begin{array}{ccc}
-1+1&amp;4+2&amp;5+3\\
1&amp;2&amp;3\\
0&amp;3&amp;-1\\
\end{array}\right]
  =
\left[\begin{array}{ccc}
0&amp;6&amp;8\\
1&amp;2&amp;3\\
0&amp;3&amp;-1\\
\end{array}\right]
  = 
B
            </mrow>
        </md>
        <p>
Express these row operations as matrix multiplication
by expressing <m>B</m> as the product of two matrices and <m>A</m>:
<me>
B =
\left[\begin{array}{ccc}
\unknown&amp;\unknown&amp;\unknown\\
\unknown&amp;\unknown&amp;\unknown\\
\unknown&amp;\unknown&amp;\unknown
\end{array}\right]
\left[\begin{array}{ccc}
\unknown&amp;\unknown&amp;\unknown\\
\unknown&amp;\unknown&amp;\unknown\\
\unknown&amp;\unknown&amp;\unknown
\end{array}\right]
A
</me>
Check your work using technology.
        </p>
    </statement>
</activity>

    <activity>
      <statement>
      <p> We have now seen how to do Gaussian elimination with matrix multiplication, if we are careful to describe our row operation with lower triangular matrices, Then we can connect matrix multiplication to finding the inverse. We will see this through the following example.
      <me>
  A = \left[\begin{array}{rrr}
  1 \amp 2 \amp 1 \\
  2 \amp 0 \amp -2 \\
  -1 \amp 2 \amp -1 \\
  \end{array}\right]
      </me>.
      When performing Gaussian elimination on <m>A</m>, we first
      apply 
      a row replacement operation in which we multiply the first
      row by <m>-2</m> and add to the second row.  After this
      step, we have a new matrix <m>A_1</m>.
      <me>
  A = \left[\begin{array}{rrr}
  1 \amp 2 \amp 1 \\
  2 \amp 0 \amp -2 \\
  -1 \amp 2 \amp -1 \\
  \end{array}\right]
  \sim
  \left[\begin{array}{rrr}
  1 \amp 2 \amp 1 \\
  0 \amp -4 \amp -4 \\
  -1 \amp 2 \amp -1 \\
  \end{array}\right]
  = A_1
      </me>.
  <ol label="a.">
    <li><p>
      Show that multiplying <m>A</m> by the lower triangular matrix
      <me>
        L_1 = \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        -2 \amp 1 \amp 0 \\
        0 \amp 0 \amp 1 \\
        \end{array}\right]
      </me> has the same effect as this row operation;  that is,
      show that <m>L_1A = A_1</m>.
    </p></li>

    <li><p> Explain why <m>L_1</m> is invertible and find its
    inverse <m>L_1^{-1}</m>.
    <sage>
      <input>
      </input>
    </sage>
    </p></li>

    <li><p> You should see that there is a simple relationship
    between <m>L_1</m> and <m>L_1^{-1}</m>.  Describe this
    relationship and explain why it holds.  </p></li>

    <li><p> To continue the Gaussian elimination algorithm, we
    need to apply two more row replacements to bring <m>A</m>
    into a triangular form <m>U</m> where
    <me>
      A = \left[\begin{array}{rrr}
      1 \amp 2 \amp 1 \\
      2 \amp 0 \amp -2 \\
      -1 \amp 2 \amp -1 \\
      \end{array}\right]
      \sim
      \left[\begin{array}{rrr}
      1 \amp 2 \amp 1 \\
      0 \amp -4 \amp -4 \\
      0 \amp 0 \amp -4 \\
      \end{array}\right] = U
    </me>.
    Find the matrices <m>L_2</m> and
    <m>L_3</m> that perform these row replacement operations so
    that <m>L_3L_2L_1 A = U</m>.
    </p></li>

    <li><p> Explain why the matrix product <m>L_3L_2L_1</m> is
    invertible and use this fact to write <m>A = LU</m>.  What
    is the matrix <m>L</m> that you find?  Why do you think we
    denote it by <m>L</m>?
    <sage>
      <input>
      </input>
    </sage>
    
    </p></li></ol></p></statement></activity>

    <activity><statement><p><ol label="a">

    <li><p> Row replacement operations may always be performed
    by multiplying by a lower triangular matrix.  It turns out
    the other two row operations, scaling and interchange, may
    also be performed using matrix multiplication.  For
    instance, consider the two matrices
    <me>
      S = \left[\begin{array}{rrr}
      1 \amp 0 \amp 0 \\
      0 \amp 3 \amp 0 \\
      0 \amp 0 \amp 1 \\
      \end{array}\right],
      \hspace{24pt}
      P = \left[\begin{array}{rrr}
      0 \amp 0 \amp 1 \\
      0 \amp 1 \amp 0 \\
      1 \amp 0 \amp 0 \\
      \end{array}\right]
    </me>.
    Show that multiplying <m>A</m> by <m>S</m> performs a
    scaling operation and that multiplying by <m>P</m> performs
    a row interchange.
    </p></li>

    <li><p> Explain why the matrices <m>S</m> and <m>P</m> are
    invertible and state their inverses.</p></li>
  </ol>
      </p>
      </statement>

      <!--<solution>
  <p><ol label="a.">
    <li><p>
      Performing the matrix multiplication, we find that
      <me>
        L_1A = 
        \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        -2 \amp 1 \amp 0 \\
        0 \amp 0 \amp 1 \\
        \end{array}\right]
        \left[\begin{array}{rrr}
        1 \amp 2 \amp 1 \\
        2 \amp 0 \amp -2 \\
        -1 \amp 2 \amp -1 \\
        \end{array}\right]
        =
        \left[\begin{array}{rrr}
        1 \amp 2 \amp 1 \\
        0 \amp -4 \amp -4 \\
        -1 \amp 2 \amp -1 \\
        \end{array}\right]\text{.}
      </me>
    </p></li>

    <li><p>
      The replacement operation is reversible;  that is, 
      multiplying the first row by <m>-2</m> and adding it to the
      second row can be undone by multiplying the first row by
      <m>2</m> and adding it to the second row.  We then expect
      that
      <m>
        L_1^{-1}
        = \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        2 \amp 1 \amp 0 \\
        0 \amp 0 \amp 1 \\
        \end{array}\right]
      </m>, which can be verified.
    </p></li>

    <li><p>
      We simply change the sign of the term that is not on the
      diagonal.
    </p></li>

    <li><p>
      Continuing with the Gaussian elimination algorithm, we
      have
      <me>
        L_2 = \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        0 \amp 1 \amp 0 \\
        1 \amp 0 \amp 1 \\
        \end{array}\right],
        L_3 = \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        0 \amp 1 \amp 0 \\
        0 \amp 1 \amp 1 \\
        \end{array}\right]\text{.}
      </me>
      we then have
      <m>L_3L_2L_1A = U</m>.
    </p></li>

    <li><p>
      Each of the matrices <m>L_1</m>, <m>L_2</m>, and
      <m>L_3</m> is invertible so their product will be as
      well.  In addition,
      <m>L = (L_3L_2L_1)^{-1} = L_1^{-1}L_2^{-1}L_3^{-1}</m>
      gives
      <m>L=\left[\begin{array}{rrr}
      1 \amp 0 \amp 0 \\
      2 \amp 1 \amp 0 \\
      -1 \amp -1 \amp 1 \\
      \end{array}\right]</m>.
    </p></li>

    <li><p>
      If we perform the matrix multiplications, we verify that
      multiplication performs the desired operation.
    </p></li>

    <li><p>
      The matrices <m>S</m> and <m>P</m> are invertible because
      each operation can be undone.  For instance, the scaling
      operation can be undone by multiplying the second row by
      <m>\frac13</m>.  The interchange operation can be undone
      by repeating the same operation.  This shows that
      <me>
        S^{-1}=
        \left[\begin{array}{rrr}
        1 \amp 0 \amp 0 \\
        0 \amp \frac13 \amp 0 \\
        0 \amp 0 \amp 1 \\
        \end{array}\right],
        P^{-1} = P =
        \left[\begin{array}{rrr}
        0 \amp 0 \amp 1 \\
        0 \amp 1 \amp 0 \\
        1 \amp 0 \amp 0 \\
        \end{array}\right]\text{.}
      </me>
    </p></li>
  </ol></p>
      </solution>-->
        
    </activity>






</section>